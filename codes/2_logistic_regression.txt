import os
import numpy as np
import tensorflow as tf
print ("PACKAGES LODAED")

# LOAD DATA
cwd = os.getcwd()
loadpath = cwd + "/data.npz"
l = np.load(loadpath)
print (l.files)

# PARSE LOADED DATA
trainimg   = l['trainimg']
trainlabel = l['trainlabel']
testimg    = l['testimg']
testlabel  = l['testlabel']
ntrain = trainimg.shape[0]
nclass = trainlabel.shape[1]
dim    = trainimg.shape[1]
ntest  = testimg.shape[0]
print ("%d TRAIN IMAGES" % (ntrain))
print ("%d TEST IMAGES" % (ntest))
print ("%d DIMENSIONAL INPUT" % (dim))
print ("%d CLASSES" % (nclass))

tf.set_random_seed(0)

# LOGISTIC REGRESSION MODEL
x = tf.placeholder("float", [None, dim]) 
y = tf.placeholder("float", [None, nclass]) 
W = tf.Variable(tf.zeros([dim, nclass]), name = 'weights')
b = tf.Variable(tf.zeros([nclass]))
def logistic_regression(_x, _W, _b):
    return tf.nn.softmax(tf.matmul(_x, _W) + _b) 
print ("LOGISTIC REGRESSION MODEL READY")

# LOSS, COST, OPTIMIZER, ACCURACY, INIT
learning_rate = 0.001
pred = logistic_regression(x, W, b)
WEIGHT_DECAY_FACTOR = 0.001
cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred)
                                     , reduction_indices=1)) 
l2_loss = tf.add_n([tf.nn.l2_loss(v) 
            for v in tf.trainable_variables()])
cost = cost + WEIGHT_DECAY_FACTOR*l2_loss
optm = tf.train.AdamOptimizer(learning_rate).minimize(cost) 
corr = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))    
accr = tf.reduce_mean(tf.cast(corr, tf.float32))
init = tf.initialize_all_variables()
print ("FUNCTIONS READY")

# PARAMETERS
batch_size      = 256
display_step    = 20
training_epochs = 400
num_batch = int(ntrain/batch_size)+1

# LAUNCH THE GRAPH
sess = tf.Session()
sess.run(init)
for epoch in range(training_epochs):
    avg_cost = 0.
    randpermlist = np.random.permutation(ntrain)
    for i in range(num_batch): 
        randidx  = randpermlist[i*batch_size:min((i+1)*batch_size, ntrain-1)]
        batch_xs = trainimg[randidx, :]
        batch_ys = trainlabel[randidx, :]                
        feeds    = {x: batch_xs, y: batch_ys}
        # OPTIMIZE VARIABLES
        sess.run(optm, feed_dict=feeds)
        # COMPUTE LOSS
        avg_cost += sess.run(cost, feed_dict=feeds)/num_batch

    # PRINT CURRENT STATUS
    if epoch % display_step == 0 or epoch == training_epochs-1:
        print ("Epoch: %03d/%03d cost: %.9f" % 
               (epoch, training_epochs, avg_cost))
        feeds = {x: trainimg, y: trainlabel}
        train_acc = sess.run(accr, feed_dict=feeds)
        feeds = {x: testimg, y: testlabel}
        test_acc = sess.run(accr, feed_dict=feeds)
        print (" TRAIN ACCURACY: %.3f" % (train_acc))
        print (" TEST ACCURACY: %.3f" % (test_acc))
print ("OPTIMIZATION FINISHED")

